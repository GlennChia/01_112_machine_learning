{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glenn Chia \n",
    "# 1003118\n",
    "# 01.112 Machine Learning Homework 2 Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. K-Means [30 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw2_qn1_path = './HW2_data/1/hw2-image.txt'\n",
    "def read_data(file_path):\n",
    "    coordintates = []\n",
    "    with open(file_path, 'r') as file_data:\n",
    "        for line in file_data.readlines():\n",
    "            line = line.rstrip('\\n')\n",
    "            coordintates.append(line.split(' '))\n",
    "    return coordintates\n",
    "coordinates = read_data(hw2_qn1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input: 2 arrays. Each array is [x, y, z]\n",
    "# output: Squared Euclidean distance\n",
    "def compute_individual_loss(point_one, point_two):\n",
    "    squared_euclidean_distance = (int(point_one[0]) - int(point_two[0])) ** 2 + (int(point_one[1]) - int(point_two[1])) ** 2 \n",
    "    + (int(point_one[2]) - int(point_two[2])) ** 2\n",
    "    return squared_euclidean_distance    \n",
    "compute_individual_loss(coordinates[0], coordinates[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255, 201, 17], [245, 124, 206], [212, 88, 187], [191, 44, 224], [55, 83, 201], [189, 250, 15], [240, 22, 157], [201, 87, 86]]\n"
     ]
    }
   ],
   "source": [
    "def generate_centroids(cluster_number=8):\n",
    "    centroids = []\n",
    "    for i in range(cluster_number):\n",
    "        centroid_x = random.randrange(0, 256) # 256 is non inclusive\n",
    "        centroid_y = random.randrange(0, 256) # 256 is non inclusive\n",
    "        centroid_z = random.randrange(0, 256) # 256 is non inclusive\n",
    "        centroid_point = [centroid_x, centroid_y, centroid_z]\n",
    "        centroids.append(centroid_point)\n",
    "    return centroids \n",
    "initial_centroids = generate_centroids(8)\n",
    "print(initial_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_array_similarity(array_one, array_two):\n",
    "    checked_index = []\n",
    "    for index_array_one, value_array_one in enumerate(array_one):\n",
    "        for index_array_two, value_array_two in enumerate(array_two):\n",
    "            if value_array_one == value_array_two and index_array_two not in checked_index:\n",
    "                checked_index.append(index_array_two)\n",
    "    if len(checked_index) == 8:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102, 48, 14], [0, 0, 0], [247, 243, 239], [0, 0, 0], [213, 209, 199], [178, 111, 58], [122, 117, 113], [22, 22, 24]]\n",
      "[[112, 50, 11], [6, 8, 9], [249, 247, 245], [0, 0, 0], [214, 177, 146], [173, 103, 49], [129, 98, 73], [30, 24, 22]]\n",
      "[[115, 51, 11], [13, 14, 17], [247, 245, 243], [1, 2, 1], [209, 154, 106], [172, 103, 50], [139, 81, 38], [37, 26, 22]]\n",
      "[[107, 49, 12], [16, 17, 19], [245, 243, 239], [3, 5, 4], [204, 145, 94], [172, 107, 57], [144, 71, 20], [43, 28, 22]]\n",
      "[[102, 48, 14], [19, 19, 21], [244, 242, 237], [5, 7, 8], [203, 143, 91], [169, 107, 58], [142, 68, 16], [46, 29, 21]]\n",
      "[[100, 48, 14], [21, 21, 23], [243, 241, 237], [7, 9, 11], [202, 141, 89], [167, 105, 57], [141, 66, 15], [49, 29, 19]]\n",
      "[[99, 47, 15], [23, 23, 24], [243, 241, 236], [10, 11, 14], [201, 140, 88], [166, 103, 56], [140, 65, 14], [52, 29, 17]]\n",
      "[[98, 47, 15], [25, 25, 26], [243, 241, 236], [12, 13, 16], [200, 139, 87], [165, 102, 55], [139, 65, 14], [56, 28, 14]]\n",
      "[[98, 47, 15], [27, 26, 28], [243, 241, 236], [13, 14, 17], [200, 139, 86], [164, 101, 54], [139, 64, 14], [59, 28, 12]]\n",
      "[[99, 47, 15], [28, 27, 28], [243, 241, 236], [14, 15, 17], [199, 138, 86], [163, 100, 53], [139, 64, 13], [60, 28, 12]]\n",
      "[[99, 48, 15], [29, 27, 28], [243, 240, 236], [14, 15, 17], [199, 138, 86], [163, 99, 52], [139, 64, 13], [61, 28, 12]]\n",
      "[[100, 48, 15], [30, 27, 28], [243, 240, 236], [14, 15, 17], [199, 137, 85], [162, 99, 51], [139, 64, 13], [61, 28, 12]]\n",
      "[[100, 48, 15], [30, 27, 28], [243, 240, 235], [15, 15, 18], [198, 137, 85], [162, 99, 51], [139, 64, 13], [62, 29, 11]]\n",
      "[[100, 48, 15], [30, 27, 28], [243, 240, 235], [15, 15, 18], [198, 137, 85], [162, 98, 51], [139, 64, 13], [62, 29, 12]]\n",
      "[[100, 48, 15], [30, 27, 28], [243, 240, 235], [15, 15, 18], [198, 137, 85], [162, 98, 50], [139, 63, 13], [62, 29, 12]]\n",
      "[[100, 48, 15], [30, 27, 28], [243, 240, 235], [15, 15, 18], [198, 137, 85], [161, 98, 50], [139, 63, 13], [62, 29, 12]]\n",
      "[[100, 48, 15], [30, 27, 28], [243, 240, 235], [15, 15, 18], [198, 137, 85], [161, 98, 50], [139, 63, 12], [62, 29, 12]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def k_means_clustering(coordinates, cluster_number, initial_centroids):\n",
    "    change_status = True\n",
    "    old_centroids = initial_centroids\n",
    "    while change_status: \n",
    "        cluster_assignment = {}\n",
    "        new_centroids = []\n",
    "        for i in range(cluster_number):\n",
    "            cluster_assignment[i] = []\n",
    "        # Cluster the points first\n",
    "        for index_coordinate, coordinate in enumerate(coordinates):\n",
    "            assignment = 8 # Something that does not make sense\n",
    "            reference_individual_loss = 70000 # Since 65025 id the largest possible squared euclidean distance\n",
    "            for index_centroid, centroid in enumerate(old_centroids):\n",
    "                new_individual_loss = compute_individual_loss(coordinate, centroid)\n",
    "                if new_individual_loss < reference_individual_loss:\n",
    "                    assignment = index_centroid\n",
    "                    reference_individual_loss = new_individual_loss\n",
    "            cluster_assignment[assignment].append(coordinate)\n",
    "        # Recalculate the centroid based on each cluster\n",
    "        for k, v in cluster_assignment.items():\n",
    "            centroid_x = 0\n",
    "            centroid_y = 0\n",
    "            centroid_z = 0\n",
    "            for cluster_count, clustered_coordinates in enumerate(v):\n",
    "                centroid_x += int(clustered_coordinates[0])\n",
    "                centroid_y += int(clustered_coordinates[1])\n",
    "                centroid_z += int(clustered_coordinates[2])\n",
    "            centroid_x /= cluster_count + 1\n",
    "            centroid_y /= cluster_count + 1\n",
    "            centroid_z /= cluster_count + 1\n",
    "            new_centroids.append([int(centroid_x), int(centroid_y), int(centroid_z)])\n",
    "        print(new_centroids)\n",
    "        # Check for centroid change\n",
    "        if (check_array_similarity(old_centroids, new_centroids)):\n",
    "            change_status = False\n",
    "            total_loss = 0\n",
    "            # Compute the loss\n",
    "        else:\n",
    "            old_centroids = new_centroids\n",
    "    return cluster_assignment, new_centroids\n",
    "cluster_assignment, new_centroids = k_means_clustering(coordinates, 8, initial_centroids)\n",
    "print(cluster_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
