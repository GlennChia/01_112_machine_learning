{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3(a) [10 points] Write a function ridge regression(tX; tY; l) that takes the training features, training responses and regularizing parameter $\\lambda$, and outputs the exact solution $\\theta$ for ridge regression. Report the resulting value of $\\theta$ for $\\lambda$ = 0.15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     y\n",
      "0    -1.13933054418729\n",
      "1    -1.38956280272455\n",
      "2    -1.46427864519255\n",
      "3   -0.771402282836843\n",
      "4    -2.45451924323433\n",
      "5    -2.53173136529269\n",
      "6   -0.585147032511934\n",
      "7    -4.53260862043966\n",
      "8   -0.593824236717293\n",
      "9    -1.38688905971912\n",
      "10   -2.49527766850141\n",
      "11   -1.73538943211652\n",
      "12    0.91300105348625\n",
      "13   -4.14696407077148\n",
      "14   -3.47921987976619\n",
      "15   -2.00766789387212\n",
      "16   -3.72876356921769\n",
      "17   -1.11373904691801\n",
      "18  -0.716923558501225\n",
      "19   -1.33254433207279\n",
      "20  -0.984736485140916\n",
      "21   -4.77208525334549\n",
      "22  -0.989487677263845\n",
      "23   0.444727886065754\n",
      "24  -0.129070694759691\n",
      "25   -2.77946763634608\n",
      "26    1.20221693265651\n",
      "27   -3.91963951568596\n",
      "28   -4.37192529305329\n",
      "29  -0.498441678852203\n",
      "30   -4.59804438953968\n",
      "31  -0.382168049862368\n",
      "32   -1.56516376434081\n",
      "33  -0.720897800318107\n",
      "34  -0.724296802078357\n",
      "35    -1.8829537957885\n",
      "36  -0.237402764116535\n",
      "37  -0.714888106720234\n",
      "38   -3.64062349641719\n",
      "39   -3.01168856716308\n",
      "40  -0.477597120292055\n",
      "41   -3.12712799176494\n",
      "42   -4.75174196842826\n",
      "43  -0.694166968747554\n",
      "44   -1.65252122013147\n",
      "45  -0.098364270780666\n",
      "46  -0.873817872518156\n",
      "47  -0.012873342457726\n",
      "48   -0.06954224996399\n",
      "49   -1.70276013102121\n",
      "The validation x is: \n",
      "[[-1.47752373 -0.0502532  -0.17023633  1.        ]\n",
      " [ 0.90709037  0.66451566  0.47865149  1.        ]\n",
      " [ 0.4003217   0.43267376 -0.43504849  1.        ]\n",
      " [-1.65365073  0.126796    1.00236757  1.        ]\n",
      " [-1.06691275 -0.83842795 -0.34888078  1.        ]\n",
      " [-0.68878191 -0.80913707  0.43642513  1.        ]\n",
      " [ 0.35745996  1.13429946  1.56657725  1.        ]\n",
      " [ 0.09528788 -2.06401766  1.04123572  1.        ]\n",
      " [ 1.23035184  1.61568621  1.48715984  1.        ]\n",
      " [-0.83620287  0.07849988  2.13596839  1.        ]]\n",
      "The test x is: \n",
      "[[-0.43319969 -0.63613778 -0.38595494  1.        ]\n",
      " [ 0.28831115  0.24175838 -0.16395618  1.        ]\n",
      " [-2.13894535  0.97237413  0.10424867  1.        ]\n",
      " [ 0.99927052 -1.11433758 -0.45458174  1.        ]\n",
      " [ 0.49052428 -0.92271326 -0.35495995  1.        ]\n",
      " [ 0.38507689  0.08352817  0.02790376  1.        ]\n",
      " [ 0.69112273 -1.00672565 -0.88943049  1.        ]\n",
      " [-0.41774901  0.40816784  1.80858458  1.        ]\n",
      " [ 0.49400495  1.02792757 -1.00655099  1.        ]\n",
      " [ 0.58197659  0.63871748 -1.42460059  1.        ]\n",
      " [-0.01784407  0.71766039 -0.61215247  1.        ]\n",
      " [ 0.87391878 -1.75733762  0.4195343   1.        ]\n",
      " [-0.66181284  0.49298387 -0.04672385  1.        ]\n",
      " [ 1.23736049  2.21406654  1.58620271  1.        ]\n",
      " [-1.0553783   0.8954994  -1.84451136  1.        ]\n",
      " [ 2.30714568  0.25333497 -0.48961114  1.        ]\n",
      " [-0.4755072   2.056542    1.57110362  1.        ]\n",
      " [ 1.41596994 -0.92738418 -0.05858269  1.        ]\n",
      " [ 1.62513334 -1.12246556 -1.09691528  1.        ]\n",
      " [ 0.40780549  1.02729963 -0.04277794  1.        ]\n",
      " [ 1.06301487 -1.61341439  0.45159474  1.        ]\n",
      " [-0.67374261  0.74646502  0.88104198  1.        ]\n",
      " [ 0.13187129  0.31486386  1.09636616  1.        ]\n",
      " [-0.21322547  0.74141203  0.80339276  1.        ]\n",
      " [ 1.05339677  1.225563    0.16642039  1.        ]\n",
      " [ 0.15524151  0.10448045 -0.52662439  1.        ]\n",
      " [-0.69002679  0.84764888 -0.15939914  1.        ]\n",
      " [-0.45254444  0.74638293 -0.14693742  1.        ]\n",
      " [ 0.99099792 -0.99198341  0.56108373  1.        ]\n",
      " [ 0.53267167 -0.61727065  0.5028914   1.        ]\n",
      " [-1.94765626  0.15310133  0.55662237  1.        ]\n",
      " [ 1.46155517 -0.28306337  1.09531722  1.        ]\n",
      " [ 0.54346479 -1.82947935 -0.0865562   1.        ]\n",
      " [-0.31688096  0.67619353  0.30241958  1.        ]\n",
      " [-0.79405799 -0.02982322 -1.87777205  1.        ]\n",
      " [ 0.27861628  1.48764306 -1.04769245  1.        ]\n",
      " [ 0.61099245  1.00413207  0.56495587  1.        ]\n",
      " [ 0.06320248  1.48185744  0.07624095  1.        ]\n",
      " [-0.97676235  0.85265757 -0.78701903  1.        ]\n",
      " [-1.93031271 -0.60963352  0.77863057  1.        ]]\n",
      "The validation y is: \n",
      "[[-1.13933054]\n",
      " [-1.3895628 ]\n",
      " [-1.46427865]\n",
      " [-0.77140228]\n",
      " [-2.45451924]\n",
      " [-2.53173137]\n",
      " [-0.58514703]\n",
      " [-4.53260862]\n",
      " [-0.59382424]\n",
      " [-1.38688906]]\n",
      "The test y is: \n",
      "[[-2.49527767]\n",
      " [-1.73538943]\n",
      " [ 0.91300105]\n",
      " [-4.14696407]\n",
      " [-3.47921988]\n",
      " [-2.00766789]\n",
      " [-3.72876357]\n",
      " [-1.11373905]\n",
      " [-0.71692356]\n",
      " [-1.33254433]\n",
      " [-0.98473649]\n",
      " [-4.77208525]\n",
      " [-0.98948768]\n",
      " [ 0.44472789]\n",
      " [-0.12907069]\n",
      " [-2.77946764]\n",
      " [ 1.20221693]\n",
      " [-3.91963952]\n",
      " [-4.37192529]\n",
      " [-0.49844168]\n",
      " [-4.59804439]\n",
      " [-0.38216805]\n",
      " [-1.56516376]\n",
      " [-0.7208978 ]\n",
      " [-0.7242968 ]\n",
      " [-1.8829538 ]\n",
      " [-0.23740276]\n",
      " [-0.71488811]\n",
      " [-3.6406235 ]\n",
      " [-3.01168857]\n",
      " [-0.47759712]\n",
      " [-3.12712799]\n",
      " [-4.75174197]\n",
      " [-0.69416697]\n",
      " [-1.65252122]\n",
      " [-0.09836427]\n",
      " [-0.87381787]\n",
      " [-0.01287334]\n",
      " [-0.06954225]\n",
      " [-1.70276013]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "with open('data/3/hw1_ridge_x.dat', 'r') as f1:\n",
    "    # next(f) # skip first row\n",
    "    df_x = pd.DataFrame((l.rstrip().split(',') for l in f1), columns=['x1','x2','x3','x4'])\n",
    "\n",
    "with open('data/3/hw1_ridge_y.dat', 'r') as f2:\n",
    "    # next(f) # skip first row\n",
    "    #df_y = pd.DataFrame()\n",
    "    #label_list = [l.rstrip().split()[0] for l in f2]\n",
    "    #print(label_list)\n",
    "    df_y = pd.DataFrame((l.rstrip().split() for l in f2), columns=['y'])\n",
    "    #df_y['y'] = label_list\n",
    "    print(df_y)\n",
    "df_x=df_x.astype(float)\n",
    "df_y=df_y.astype(float)\n",
    "\n",
    "vX = df_x.head(10).values\n",
    "tX = df_x.tail(40).values\n",
    "vY = np.array(df_y.head(10))\n",
    "tY = np.array(df_y.tail(40))\n",
    "print('The validation x is: \\n{}'.format(vX))\n",
    "print('The test x is: \\n{}'.format(tX))\n",
    "print('The validation y is: \\n{}'.format(vY))\n",
    "print('The test y is: \\n{}'.format(tY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57939825],\n",
       "       [ 1.15033028],\n",
       "       [ 0.04934122],\n",
       "       [-1.59867896]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ridgeregression(tX, tY, l):\n",
    "    first_dimension = tX.shape[0]\n",
    "    second_dimension = tX.shape[1]\n",
    "    identity_matrix = np.identity(second_dimension)\n",
    "    n_lambda_i = first_dimension * l * identity_matrix\n",
    "    xt_x = np.transpose(tX).dot(tX)\n",
    "    xt_y = np.transpose(tX).dot(tY)\n",
    "    add_matrix = n_lambda_i + xt_x\n",
    "    inverse_matrix = np.linalg.inv(add_matrix)\n",
    "    weight = inverse_matrix.dot(xt_y)\n",
    "    return weight\n",
    "ridgeregression(tX, tY,0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3(b) [10 points] Use the following code to plot graphs of the validation loss and training loss as $\\lambda$ varies on logarithmic scale from $\\lambda$ = 10<sup>-5</sup> to $\\lambda$ = 10<sup>0</sup>. Write down the value of $\\lambda$ that minimizes the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19dc1c1b1d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches \n",
    "tn = tX.shape[0]\n",
    "vn = vX.shape[0]\n",
    "tloss = []\n",
    "vloss = []\n",
    "index = -np.arange(0, 5, 0.1)\n",
    "lowest_index = 0.0\n",
    "lowest_validation_loss = 100.0\n",
    "for i in index:\n",
    "    if i == 0.0:\n",
    "        lowest_index = i\n",
    "        lowest_validation_loss = np.sum((np.dot(vX, w) - vY) ** 2 )/vn/2\n",
    "    w = ridgeregression(tX, tY, 10 ** i )\n",
    "    tloss = tloss + [np.sum((np.dot(tX, w) - tY) ** 2 )/tn/2]\n",
    "    vloss = vloss + [np.sum((np.dot(vX, w) - vY) ** 2 )/vn/2]\n",
    "    current_validation_loss = np.sum((np.dot(vX, w) - vY) ** 2 )/vn/2\n",
    "    if current_validation_loss < lowest_validation_loss:\n",
    "        lowest_validation_loss = current_validation_loss\n",
    "        lowest_index = i\n",
    "plt.plot(index,np.log(tloss),'r')\n",
    "plt.plot(index,np.log(vloss), 'b')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Validation Loss')\n",
    "red_patch = mpatches.Patch(color='red', label='Training Loss')\n",
    "plt.legend(handles=[blue_patch, red_patch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The power to the lambda that minimizes the validation loss is -1.9, \n",
      "with a validation loss of 0.007627810885830868\n"
     ]
    }
   ],
   "source": [
    "print('''The power to the lambda that minimizes the validation loss is {}, \n",
    "with a validation loss of {}'''.format(lowest_index.round(3), lowest_validation_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The value of $\\lambda$ that minmizes the validation loss is $\\lambda$= 10<sup>-1.9</sup>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
